{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation\n",
    "from PIL import Image, ImageFilter\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import gradio as gr\n",
    "\n",
    "processor = SegformerImageProcessor.from_pretrained(\"mattmdjaga/segformer_b2_clothes\")\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(\"mattmdjaga/segformer_b2_clothes\")\n",
    "\n",
    "title = \"Background remover ðŸ‘€\"\n",
    "description = \" Image segmentation model which removes the background and optionally adds a white border.\"\n",
    "article = 'Inference done on \"mattmdjaga/segformer_b2_clothes\" model'\n",
    "\n",
    "\n",
    "folder_path = \"Images\" \n",
    "example_list = []\n",
    "if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "    file_paths = [os.path.join(folder_path, file_name) for file_name in os.listdir(folder_path)]\n",
    "    for file_path in file_paths:\n",
    "        example_list.append(['Large',file_path])\n",
    "\n",
    "def predict(border_size, image):\n",
    "    sizes = {'Large': 5, 'Medium': 3, 'Small': 1, 'None': 0}\n",
    "    image = image.convert('RGB')\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits.cpu()\n",
    "\n",
    "    upsampled_logits = nn.functional.interpolate(\n",
    "        logits,\n",
    "        size=image.size[::-1],\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    pred_seg = upsampled_logits.argmax(dim=1)[0]\n",
    "\n",
    "    non_background_mask = pred_seg != 0\n",
    "\n",
    "    # Convert tensor mask to PIL Image with an alpha channel\n",
    "    non_background_pil_mask = Image.fromarray(non_background_mask.numpy().astype('uint8') * 255, 'L')\n",
    "\n",
    "    # Create a composite image using the non-background mask\n",
    "    composite_image = Image.new('RGBA', image.size, color=(0, 0, 0, 0))\n",
    "    composite_image.paste(image.convert('RGBA'), mask=non_background_pil_mask)\n",
    "\n",
    "    if sizes[border_size] != 0:\n",
    "        stroke_radius = sizes[border_size]\n",
    "        img = composite_image # RGBA image\n",
    "        stroke_image = Image.new(\"RGBA\", img.size, (255, 255, 255, 255))\n",
    "        img_alpha = img.getchannel(3).point(lambda x: 255 if x>0 else 0)\n",
    "        stroke_alpha = img_alpha.filter(ImageFilter.MaxFilter(stroke_radius))\n",
    "        stroke_alpha = stroke_alpha.filter(ImageFilter.SMOOTH)\n",
    "        stroke_image.putalpha(stroke_alpha)\n",
    "        output = Image.alpha_composite(stroke_image, img)\n",
    "        return output\n",
    "    else:\n",
    "        return composite_image\n",
    "    \n",
    "iface = gr.Interface(fn=predict,\n",
    "                    inputs=[gr.Dropdown(['None','Small', 'Medium', 'Large'], label='Select Border Size'),\n",
    "                            gr.Image(type='pil', label='Select Image.')],\n",
    "                    outputs=gr.Image(type='pil', label='Output with background removed (sorta?)'),\n",
    "                             title=title,\n",
    "                             description=description,\n",
    "                             article=article,\n",
    "                             examples=example_list)\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
